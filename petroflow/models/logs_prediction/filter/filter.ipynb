{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logs data filtering for DT prediction model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "sys.path.insert(0, \"/notebooks/goryachev/petroflow\")\n",
    "\n",
    "from petroflow import Well, WellDataset\n",
    "from petroflow.batchflow import Pipeline\n",
    "from petroflow.models.logs_prediction.utils import build_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filtering pipeline actions, explained.\n",
    "\n",
    "* `keep_logs(PROPER_COL)` — drop all columns from logs, except `PROPER_COL`\n",
    "* `drop_nans(PROPER_COL)` — split logs into non-nan segments\n",
    "* `drop_short_segments(CROP_LENGTH)` — drop segments shorter than `CROP_LENGTH`\n",
    "* `reindex(REINDEXATION_STEP, attrs='logs')` — reindex all logs to `REINDEXATION_STEP` step\n",
    "* `interpolate(attrs=\"logs\", limit_direction=\"both\")` — fill nans produces by interpolation\n",
    "* `norm_mean_std()` — normalize logs data\n",
    "* `add_depth_log()` — add `DEPTH` column to logs\n",
    "* `apply(lambda x: x / 1000, src='DEPTH')` — convert `DEPTH` column to kilometers\n",
    "* `rename_logs({'DEPTH': 'DEPTH KM'})` — rename `DEPTH` column to avoid error on dump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/pandas/core/frame.py:3940: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "\n"
     ]
    }
   ],
   "source": [
    "RAW_DATASET_PATH = \"../data/raw/*\"\n",
    "raw_dataset = WellDataset(path=RAW_DATASET_PATH, dirs=True)\n",
    "\n",
    "INPUTS_COL = ['GK', 'NKTD', 'GZ1']\n",
    "TARGET_COL = ['DT']\n",
    "PROPER_COL = INPUTS_COL + TARGET_COL\n",
    "\n",
    "CROP_SIZE = 64\n",
    "REINDEXATION_STEP = 0.1\n",
    "CROP_LENGTH = CROP_SIZE * REINDEXATION_STEP\n",
    "\n",
    "filtering_template = (Pipeline()\n",
    "    .keep_logs(PROPER_COL)\n",
    "    .drop_nans(PROPER_COL)\n",
    "    .drop_short_segments(CROP_LENGTH)\n",
    "    .reindex(REINDEXATION_STEP, attrs='logs')\n",
    "    .interpolate(attrs=\"logs\", limit_direction=\"both\")\n",
    "    .norm_mean_std()\n",
    "    .add_depth_log()\n",
    "    .apply(lambda x: x / 1000, src='DEPTH')\n",
    "    .rename_logs({'DEPTH': 'DEPTH KM'})\n",
    ")\n",
    "\n",
    "filtering_pipeline = raw_dataset >> filtering_template\n",
    "filtered_batch = filtering_pipeline.next_batch(raw_dataset.size)\n",
    "filtered_dataset = build_dataset(filtered_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save filtered dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILTERED_DATASET_PATH = \"../data/filtered/\"\n",
    "for well in filtered_dataset.wells:\n",
    "    well.dump(FILTERED_DATASET_PATH)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
