{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lithology prediction by core images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import collections\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import time\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"#,1,2,4\"\n",
    "\n",
    "sys.path.insert(0, os.path.join(\"..\", \"..\", \"..\"))\n",
    "\n",
    "from petroflow.batchflow.models.torch import UNet, ResNet18, ResNet34\n",
    "from petroflow.batchflow import Dataset, FilesIndex, Pipeline, V, B, inbatch_parallel, I, W, F, ImagesBatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import shutil\n",
    "\n",
    "# for item in list(os.walk('/notebooks/data/august_dataset/crops'))[0][1]:\n",
    "#     if item not in ['Песчаник', 'Алевролит', 'Уголь', 'Аргиллит']:\n",
    "#         shutil.move('/notebooks/data/august_dataset/crops/'+item, '/notebooks/data/august_dataset/other_crops/'+item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = FilesIndex(path='/notebooks/data/august_dataset/crops/*/*_dl.png')\n",
    "ds = Dataset(index=index, batch_class=ImagesBatch)\n",
    "ds.split(0.8, shuffle=42)\n",
    "\n",
    "annotation = pd.read_feather('/notebooks/data/august_dataset/crops/annotation.feather')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotation.NAME += '_dl.png'\n",
    "annotation = annotation.set_index('NAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_ppl = (\n",
    "    Pipeline()\n",
    "    .load(fmt='image', dst='images')\n",
    "    .load(src=annotation.LITHOLOGY, dst='labels')\n",
    "    .update(B('labels'), B('labels').values)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter_ppl = (\n",
    "    Pipeline()\n",
    "    .init_variable('lithology', default=[])\n",
    "    .update(V('lithology', mode='e'), B('labels'))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import collections\n",
    "\n",
    "# ppl = (load_ppl + counter_ppl << ds)\n",
    "# (ppl\n",
    "#  .after\n",
    "#  .add_namespace(collections)\n",
    "#  .init_variable('counter')\n",
    "#  .Counter(V('lithology'), save_to=V('counter'))\n",
    "# )\n",
    "\n",
    "# ppl.run(10, bar=True, n_epochs=1)\n",
    "# ppl.v('counter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Алевролит': 2, 'Аргиллит': 1, 'Песчаник': 3, 'Уголь': 0}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# labels_mapping = {i: k for k, i in enumerate(ppl.v('counter'))}\n",
    "\n",
    "# with open('resnet/labels_mapping', 'wb') as f:\n",
    "#     pickle.dump(labels_mapping, f)\n",
    "\n",
    "with open('resnet/labels_mapping', 'rb') as f:\n",
    "    labels_mapping = pickle.load(f)\n",
    "\n",
    "reverse_mapping = {v: k for k, v in labels_mapping.items()}\n",
    "labels_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(labels, mapping):\n",
    "    return np.array([mapping[item] for item in labels])\n",
    "\n",
    "BATCH_SIZE = 8\n",
    "N_EPOCH = 50\n",
    "SHAPE = (3, 500, 250)\n",
    "\n",
    "model_config = {'initial_block/inputs': 'images',\n",
    "                'inputs/images/shape': SHAPE,\n",
    "                'inputs/labels/classes': len(labels_mapping),\n",
    "                'initial_block/inputs': 'images',\n",
    "                'optimizer': 'Adam',\n",
    "                'output': 'proba',\n",
    "                'device': 'gpu:0',\n",
    "                'loss': 'ce'}\n",
    "\n",
    "train_tmp = (Pipeline()\n",
    "    .add_namespace(np)\n",
    "    .crop(src='images', dst='images', origin='random', shape=(SHAPE[2], SHAPE[1]))\n",
    "    .to_array(src='images', dst='images', dtype='float32')\n",
    "    .init_variable('loss', default=[])\n",
    "    .transpose(B('images'), axes=(0, 3, 1, 2), save_to=B('images'))\n",
    "    .encode(B('labels'), labels_mapping, save_to=B('labels'))\n",
    "    .init_model('dynamic', ResNet18, 'model', model_config)\n",
    "    .train_model('model', B('images'), B('labels'), use_lock=True, fetches='loss',\n",
    "             save_to=V('loss', mode='a'))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 541/27294 [02:42<2:39:21,  2.80it/s]"
     ]
    }
   ],
   "source": [
    "train_ppl = (load_ppl + train_tmp << ds.train)\n",
    "train_ppl.run(16, n_epochs=100, shuffle=42, bar=True, prefetch=3)#, bar_desc=W(V('loss')[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.array(train_ppl.v('loss')))\n",
    "plt.plot(pd.Series(np.array(train_ppl.v('loss'))).rolling(100).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "with open('resnet/loss', 'rb') as f:\n",
    "    loss = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(loss)\n",
    "plt.plot(pd.Series(np.array(loss)).rolling(100).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ppl.get_model_by_name('model').save('resnet/model.torch')\n",
    "\n",
    "with open('resnet/loss', 'wb') as f:\n",
    "    pickle.dump(train_ppl.get_variable('loss'), f)\n",
    "\n",
    "with open('resnet/dataset', 'wb') as f:\n",
    "    pickle.dump(ds, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_tmp = (Pipeline()\n",
    "    .add_namespace(np)\n",
    "    .crop(src='images', dst='images', origin='random', shape=(SHAPE[2], SHAPE[1]))\n",
    "    .to_array(src='images', dst='images', dtype='float32')\n",
    "    .init_variable('metrics', default=None)\n",
    "    .transpose(B('images'), axes=(0, 3, 1, 2), save_to=B('images'))\n",
    "    .encode(B('labels'), labels_mapping, save_to=B('labels'))\n",
    "    .init_model('dynamic', ResNet18, 'model', config={\n",
    "                    'device': 'gpu:1', 'load/path': 'resnet/model.torch'\n",
    "                })\n",
    "    .predict_model('model', B('images'), fetches='proba', save_to=B('proba'))\n",
    "    .gather_metrics('class', targets=B('labels'), predictions=B('proba'),\n",
    "                    fmt='proba', axis=-1, save_to=V('metrics', mode='u'))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ppl = (load_ppl + test_tmp << ds.test)\n",
    "test_ppl.run(64, n_epochs=1, bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_metrics = test_ppl.get_variable('metrics')\n",
    "print(val_metrics._confusion_matrix)\n",
    "\n",
    "for m in ['specificity', 'sensitivity', 'accuracy', 'f1_score']:\n",
    "    print(m, ':', val_metrics.evaluate(m))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_ppl = (load_ppl + test_tmp << ds.test)\n",
    "b = example_ppl.next_batch(64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "for i in range(len(b.images)):\n",
    "    image = b.images[i].transpose((2, 1, 0))\n",
    "    target = reverse_mapping[b.labels[i]]\n",
    "    pred = reverse_mapping[b.proba[i].argmax()]\n",
    "\n",
    "\n",
    "    plt.figure(figsize=(5, 10))\n",
    "    plt.imshow(image / 255)\n",
    "    plt.title(target + '     ' + pred, color='g' if target == pred else 'r')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
