{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lithology prediction by core images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import collections\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import time\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"#,1,2,4\"\n",
    "\n",
    "sys.path.insert(0, os.path.join(\"..\", \"..\", \"..\"))\n",
    "\n",
    "from petroflow import CoreBatch, CoreIndex\n",
    "from petroflow.batchflow.models.torch import ResNet18\n",
    "from petroflow.batchflow import Dataset, FilesIndex, Pipeline, V, B, inbatch_parallel, I, W, F, ImagesBatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = '/notebooks/data/august_dataset/cropped_wells/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load_ppl = (Pipeline()\n",
    "#     .load(uv=False, dst='dl')\n",
    "#     .normalize(src='dl', dst='dl')\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import PIL, cv2\n",
    "\n",
    "# image = PIL.Image.open('/notebooks/data/august_dataset/cropped_wells/770_воргенское/samples_dl/2634.13_2635.87.png')\n",
    "# # image = np.array(image)\n",
    "# # image = cv2.cvtColor(image.astype('uint8'), cv2.COLOR_RGB2YCrCb)\n",
    "# # image[:,:,0] = cv2.equalizeHist(image[:,:,0])\n",
    "# # image = cv2.cvtColor(image, cv2.COLOR_YCrCb2RGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# b = (load_ppl << ds).next_batch(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.array(b.dl[0]).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = CoreIndex(path=PATH)\n",
    "\n",
    "annotation = pd.read_feather('/notebooks/data/august_dataset/cropped_wells/annotation.feather')\n",
    "annotation['SAMPLE'] = annotation['WELL'] + '_' + annotation['SAMPLE']\n",
    "annotation = annotation.set_index('SAMPLE')\n",
    "\n",
    "annotation = annotation[annotation['LITHOLOGY'].isin(['Песчаник', 'Алевролит', 'Аргиллит', 'Уголь'])]\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "train_wells = np.random.choice(annotation.WELL.unique(), int(len(annotation.WELL.unique()) * 0.8), replace=False)\n",
    "test_wells = np.setdiff1d(annotation.WELL.unique(), train_wells)\n",
    "\n",
    "index = index.create_subset(annotation.index.values)\n",
    "train_index = index.create_subset(annotation[annotation.WELL.isin(train_wells)].index.values)\n",
    "test_index = index.create_subset(annotation[annotation.WELL.isin(test_wells)].index.values)\n",
    "\n",
    "ds = Dataset(index, CoreBatch)\n",
    "ds_train = Dataset(train_index, CoreBatch)\n",
    "ds_test = Dataset(test_index, CoreBatch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train/test ratio: 3.79701230228471\n"
     ]
    }
   ],
   "source": [
    "print('Train/test ratio:', len(ds_train.indices) / len(ds_test.indices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_ppl = (\n",
    "    Pipeline()\n",
    "    .load(uv=False, dst=['dl'])\n",
    "    .create_labels(annotation.LITHOLOGY.loc)\n",
    "    .update(B('labels'), B('labels').tolist())\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter_ppl = (\n",
    "    Pipeline()\n",
    "    .init_variable('lithology', default=[])\n",
    "    .update(V('lithology', mode='e'), B('labels'))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import collections\n",
    "\n",
    "# ppl = (load_ppl + counter_ppl << ds_train)\n",
    "# (ppl\n",
    "#  .after\n",
    "#  .add_namespace(collections)\n",
    "#  .init_variable('counter')\n",
    "#  .Counter(V('lithology'), save_to=V('counter'))\n",
    "# )\n",
    "\n",
    "# ppl.run(10, bar=True, n_epochs=1)\n",
    "# ppl.v('counter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Алевролит': 1, 'Аргиллит': 0, 'Песчаник': 3, 'Уголь': 2}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# labels_mapping = {i: k for k, i in enumerate(ppl.v('counter'))}\n",
    "\n",
    "# with open('resnet/labels_mapping', 'wb') as f:\n",
    "#     pickle.dump(labels_mapping, f)\n",
    "\n",
    "with open('resnet/labels_mapping', 'rb') as f:\n",
    "    labels_mapping = pickle.load(f)\n",
    "\n",
    "reverse_mapping = {v: k for k, v in labels_mapping.items()}\n",
    "labels_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(labels, mapping):\n",
    "    return np.array([mapping[item] for item in labels])\n",
    "\n",
    "BATCH_SIZE = 8\n",
    "N_EPOCH = 50\n",
    "SHAPE = (3, 500, 250)\n",
    "\n",
    "model_config = {'initial_block/inputs': 'images',\n",
    "                'inputs/images/shape': SHAPE,\n",
    "                'inputs/labels/classes': len(labels_mapping),\n",
    "                'initial_block/inputs': 'images',\n",
    "                'optimizer': 'Adam',\n",
    "                'output': 'proba',\n",
    "                'device': 'gpu:0',\n",
    "                'loss': 'ce'}\n",
    "\n",
    "train_tmp = (Pipeline()\n",
    "    .add_namespace(np)\n",
    "    .to_array(src='dl', dst='images', dtype='float32')\n",
    "    .make_random_crops(src=['images'], dst=['images'], channels='last', shape=SHAPE[1:], n_crops=1)\n",
    "    .concatenate(B('images'), axis=0, save_to=B('images'))\n",
    "    .init_variable('loss', default=[])\n",
    "    .transpose(B('images'), axes=(0, 3, 1, 2), save_to=B('images'))\n",
    "    .encode(B('labels'), labels_mapping, save_to=B('labels'))\n",
    "    .init_model('dynamic', ResNet18, 'model', model_config)\n",
    "    .train_model('model', B('images'), B('labels'), use_lock=True, fetches='loss',\n",
    "             save_to=V('loss', mode='a'))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 57/27007 [00:26<5:23:47,  1.39it/s]"
     ]
    }
   ],
   "source": [
    "train_ppl = (load_ppl + train_tmp << ds_train)\n",
    "train_ppl.run(16, n_epochs=100, shuffle=42, bar=True, prefetch=3)#, bar_desc=W(V('loss')[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.array(train_ppl.v('loss')))\n",
    "plt.plot(pd.Series(np.array(train_ppl.v('loss'))).rolling(100).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "with open('resnet/loss', 'rb') as f:\n",
    "    loss = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(loss)\n",
    "plt.plot(pd.Series(np.array(loss)).rolling(100).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ppl.get_model_by_name('model').save('resnet/model1.torch')\n",
    "\n",
    "with open('resnet/loss', 'wb') as f:\n",
    "    pickle.dump(train_ppl.get_variable('loss'), f)\n",
    "\n",
    "with open('resnet/dataset', 'wb') as f:\n",
    "    pickle.dump(ds, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_tmp = (Pipeline()\n",
    "    .add_namespace(np)\n",
    "    .to_array(src='dl', dst='images', dtype='float32')\n",
    "    .make_random_crops(src=['images'], dst=['images'], channels='last', shape=SHAPE[1:], n_crops=1)\n",
    "    .concatenate(B('images'), axis=0, save_to=B('images'))\n",
    "    .init_variable('metrics', default=None)\n",
    "    .transpose(B('images'), axes=(0, 3, 1, 2), save_to=B('images'))\n",
    "    .encode(B('labels'), labels_mapping, save_to=B('labels'))\n",
    "    .init_model('dynamic', ResNet18, 'model', config={\n",
    "                    'device': 'gpu:0', 'load/path': 'resnet/model1.torch'\n",
    "                })\n",
    "    .predict_model('model', B('images'), fetches='proba', save_to=B('proba'))\n",
    "    .gather_metrics('class', targets=B('labels'), predictions=B('proba'),\n",
    "                    fmt='proba', axis=-1, save_to=V('metrics', mode='u'))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ppl = (load_ppl + test_tmp << ds_test)\n",
    "test_ppl.run(64, n_epochs=1, bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_metrics = test_ppl.get_variable('metrics')\n",
    "print(val_metrics._confusion_matrix)\n",
    "\n",
    "for m in ['specificity', 'sensitivity', 'accuracy', 'f1_score']:\n",
    "    print(m, ':', val_metrics.evaluate(m))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_ppl = (load_ppl + test_tmp << ds_test)\n",
    "b = example_ppl.next_batch(64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "for i in range(len(b.images)):\n",
    "    image = b.images[i].transpose((2, 1, 0))\n",
    "    target = reverse_mapping[b.labels[i]]\n",
    "    pred = reverse_mapping[b.proba[i].argmax()]\n",
    "\n",
    "\n",
    "    plt.figure(figsize=(5, 10))\n",
    "    plt.imshow(image / 255)\n",
    "    plt.title(target + '     ' + pred, color='g' if target == pred else 'r')\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
