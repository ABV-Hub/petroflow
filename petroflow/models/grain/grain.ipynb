{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import shutil\n",
    "\n",
    "sys.path.insert(0, os.path.join(\"..\", \"..\", \"..\"))\n",
    "\n",
    "from petroflow import Well, WellBatch, WS, WellDataset\n",
    "from petroflow.batchflow.models.torch import UNet, ResNet18, ResNet34\n",
    "from petroflow.batchflow import Dataset, DatasetIndex, FilesIndex, Pipeline, V, B, action, inbatch_parallel, I, W, F, L, ImagesBatch, R, P"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Auxilary functions/classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class MyWellBatch(WellBatch):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, pixels_per_cm=25, **kwargs)\n",
    "    \n",
    "    @action\n",
    "    def create_images_batch(self, core_dl, core_uv, targets):\n",
    "        index = DatasetIndex(len(core_dl))\n",
    "        batch = ImagesBatch(index)\n",
    "        batch = batch.add_components(('core_dl', 'core_uv', 'targets'),\n",
    "                                     (np.array(core_dl).astype(np.uint8),\n",
    "                                      np.array(core_uv).astype(np.uint8),\n",
    "                                      np.array(targets)))\n",
    "        return batch\n",
    "\n",
    "class softCrossEntropy(nn.Module):\n",
    "    def __init__(self, weights):\n",
    "        super().__init__()\n",
    "        self.weights = weights\n",
    "        return\n",
    "\n",
    "    def forward(self, inputs, target):\n",
    "        \"\"\"\n",
    "        :param inputs: predictions\n",
    "        :param target: target labels\n",
    "        :return: loss\n",
    "        \"\"\"\n",
    "        log_likelihood = - F.log_softmax(inputs, dim=1)\n",
    "        log_likelihood *= self.weights\n",
    "        sample_num, class_num = target.shape\n",
    "        loss = torch.sum(torch.mul(log_likelihood, target)) / sample_num\n",
    "\n",
    "        return loss\n",
    "\n",
    "def mydump(iteration):\n",
    "    import pickle\n",
    "    with open('flag', 'wb') as f:\n",
    "        pickle.dump(iteration, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "N_CROPS = 16\n",
    "N_EPOCH = 500\n",
    "LENGTH = 0.1\n",
    "SHAPE = (6, int(2500 * LENGTH), 250)\n",
    "\n",
    "CLASSES = ['GRAVEL', 'SAND', 'ALEURITE', 'CLAY']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filter wells without grain table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 21/21 [00:00<00:00, 78.17it/s]\n"
     ]
    }
   ],
   "source": [
    "index = FilesIndex(path='/notebooks/data/september_dataset/core_photo/*/*', dirs=True)\n",
    "ds = Dataset(index=index, batch_class=MyWellBatch)\n",
    "\n",
    "filter_ppl = (ds.p\n",
    "              .init_variable('wells', default=[])\n",
    "              .has_attr('grain')\n",
    "              .update(V('wells', mode='e'), B().indices)\n",
    "              .run(10, n_epochs=1, shuffle=False, bar=True))\n",
    "\n",
    "filtered_index = index.create_subset(filter_ppl.v('wells'))\n",
    "ds = Dataset(index=filtered_index, batch_class=MyWellBatch)\n",
    "ds.split()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute weights for loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = pd.read_feather('/notebooks/data/september_dataset/grain.feather')[CLASSES].mean() / 100\n",
    "weights = 1 / weights\n",
    "weights = np.clip(weights, 0, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "crops_template = (Pipeline()\n",
    "    .create_segments(src='samples', connected=True)\n",
    "    .create_segments(src='grain', length=2 * LENGTH)\n",
    "    .random_crop(length=LENGTH, n_crops=N_CROPS)\n",
    "    .drop_short_segments(LENGTH)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "components_template = (Pipeline()\n",
    "    .update(B('core'), (WS('core_dl').ravel(), WS('core_uv').ravel()))\n",
    "    .update(B('targets'), WS('grain')[CLASSES].mean().values.ravel())\n",
    "    .create_images_batch(B('core')[0], B('core')[1], B('targets'))\n",
    "    .to_pil(src=['core_dl', 'core_uv'], dst=['core_dl', 'core_uv'])\n",
    ")\n",
    "\n",
    "augmentation_template = (Pipeline()\n",
    "    .cutout(shape=P((R(np.arange(100, 200)), R(np.arange(100, 200)))),\n",
    "            origin=P((R('uniform'), R('uniform'))),\n",
    "            color=0, src=['core_dl', 'core_uv'], dst=['core_dl', 'core_uv'])\n",
    ")\n",
    "\n",
    "concat_template = (Pipeline()\n",
    "    .add_namespace(np)\n",
    "    .to_array(src=['core_dl', 'core_uv'], dst=['core_dl', 'core_uv'])\n",
    "    .concatenate((B('core_dl'), B('core_uv')), axis=-1, save_to=B('crops'))\n",
    "    .transpose(B('crops'), axes=(0, 3, 1, 2), save_to=B('crops'))\n",
    "    .nan_to_num(B('crops'), save_to=B('crops'))\n",
    "    .array(B('crops'), dtype='float32', save_to=B('crops'))\n",
    "    .array(B('targets'), dtype='float32', save_to=B('targets'))\n",
    ")\n",
    "\n",
    "model_config = {'initial_block/inputs': 'images',\n",
    "                'inputs/images/shape': SHAPE,\n",
    "                'inputs/labels/classes': 4,\n",
    "                'optimizer': 'Adam',#('SGD', dict(lr=0.01, momentum=0.95)),\n",
    "                'device': 'gpu:1',\n",
    "                'output': 'proba',\n",
    "                'microbatch': N_CROPS,\n",
    "                'loss': (softCrossEntropy, {'weights': torch.tensor(weights).to('cuda:1')})}\n",
    "        \n",
    "train_template = (Pipeline()\n",
    "    .init_variable('loss_history', default=[])\n",
    "    .init_model('dynamic', ResNet18, 'model', model_config)\n",
    "    .mydump(I())\n",
    "    .train_model('model', B('crops'), B('targets') / 100, fetches='loss', save_to=V('loss_history', mode='a'))\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ppl = (crops_template + \n",
    "       components_template +\n",
    "       augmentation_template @ 0.33 +\n",
    "       concat_template +\n",
    "       train_template\n",
    "      ) << ds.train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#b = ppl.next_batch(16)\n",
    "#b.crops.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(10, 10))\n",
    "# for i, crop in enumerate(np.array(b.crops_dl)):\n",
    "#     plt.subplot(BATCH_SIZE, N_CROPS, i+1)\n",
    "#     plt.title((\"{:3.0f}, \"*4)[:-2].format(*b.targets[i]))\n",
    "#     plt.imshow(crop / 255)\n",
    "#     plt.xticks([])\n",
    "#     plt.yticks([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.read_feather('/notebooks/data/september_dataset/core_photo/Восточно-Мессояхское/123_восточно-мессояхское/grain.feather')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2000 [00:00<?, ?it/s]/usr/local/lib/python3.5/dist-packages/pandas/core/frame.py:3940: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "\n",
      "0.15614183:   1%|          | 12/2000 [04:09<11:17:57, 20.46s/it]"
     ]
    }
   ],
   "source": [
    "ppl.run(BATCH_SIZE, n_epochs=N_EPOCH, bar=True, shuffle=True,\n",
    "        drop_last=True, bar_desc=W(V('loss_history')[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "ppl.get_model_by_name('model').save('model.torch')\n",
    "\n",
    "with open('loss', 'wb') as f:\n",
    "    pickle.dump(ppl.get_variable('loss_history'), f)\n",
    "\n",
    "with open('dataset', 'wb') as f:\n",
    "    pickle.dump(ds, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('loss', 'rb') as f:\n",
    "    loss = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "plt.plot(loss)\n",
    "plt.plot(pd.Series(np.array(loss)).rolling(100).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_test = (Pipeline()\n",
    "    .create_segments(src='samples', connected=True)\n",
    "    .create_segments(src='grain', length=LENGTH)\n",
    ")\n",
    "\n",
    "test_template = (Pipeline()\n",
    "    .init_variable('lithology', default=[])\n",
    "    .update(V('lithology', mode='e'), WS('grain').iloc[0].ravel())\n",
    "    .init_variable('predictions', default=[])\n",
    "    .init_model('dynamic', ResNet18, 'model', config={\n",
    "                    'device': 'cpu', 'load/path': 'model.torch'\n",
    "                })\n",
    "    .predict_model('model', B('crops'), fetches='proba', save_to=V('predictions', mode='e')) \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ppl = (split_test + reg_template + test_template) << ds.test\n",
    "ppl.run(1, n_epochs=1, bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = pd.concat(ppl.v('lithology'), axis=1).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "values = np.array(ppl.v('predictions')) * 100\n",
    "pred = pd.DataFrame({\n",
    "    'GRAVEL_PRED': values[:, 0],\n",
    "    'SAND_PRED': values[:, 1],\n",
    "    'ALEURITE_PRED': values[:, 2],\n",
    "    'CLAY_PRED': values[:, 3]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.concat([target.reset_index(), pred], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results['LITHOLOGY'] = results.LITHOLOGY.apply(lambda x: x.split(' ')[0].capitalize())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ['Песчаник', 'Алевролит', 'Глина']\n",
    "colors = ['r', 'g', 'b', 'y']\n",
    "\n",
    "mask = [np.isin(item, classes) for item in results.LITHOLOGY]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grain.columns[3:7]\n",
    "from sklearn.manifold import TSNE\n",
    "tsne_res = TSNE(n_components=2, n_iter_without_progress=500).fit_transform(results[\n",
    "    ['GRAVEL_PRED', 'SAND_PRED', 'ALEURITE_PRED', 'CLAY_PRED']\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "for label, color in zip(classes, colors):\n",
    "    plt.scatter(tsne_res[(results.LITHOLOGY == label).values, 0],\n",
    "                tsne_res[(results.LITHOLOGY == label).values, 1], color=color, label=label)\n",
    "\n",
    "plt.title('Данные гранулометрии')\n",
    "plt.legend()\n",
    "plt.xticks([])\n",
    "plt.yticks([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
