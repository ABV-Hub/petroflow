{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Исправление разметки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import glob\n",
    "\n",
    "sys.path.insert(0, os.path.join(\"..\", \"..\", \"..\"))\n",
    "\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import PIL\n",
    "from PIL import Image\n",
    "\n",
    "from well_logs import CoreBatch\n",
    "from well_logs.batchflow import Dataset, Pipeline, B, V, FilesIndex\n",
    "from well_logs.batchflow.models.torch import ResNet18\n",
    "from utils import plot_pair, make_data, get_bounds, assemble, plot_images_predictions, plot_crops_predictions, fix_annotation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузим разметку для отложенной скважины"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = '/notebooks/data/processed_dataset/509'\n",
    "\n",
    "index = FilesIndex(path=os.path.join(PATH, 'samples_dl/*.png'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Предобработка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([pd.read_feather(filename) for filename in glob.glob(PATH+'/samples.feather')])\n",
    "df['QC'] = 1 - df['QC']\n",
    "df = df.set_index('SAMPLE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = index.create_subset(np.intersect1d(df.index.values, index.indices))\n",
    "ds = Dataset(index, CoreBatch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "SHAPE = (2, 400, 150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<well_logs.batchflow.batchflow.pipeline.Pipeline at 0x7f07c4d074a8>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shape_ppl = (ds.p\n",
    "     .load()\n",
    "     .check_shapes(dst='check')\n",
    "     .init_variable('quality', init_on_each_run=list)\n",
    "     .update_variable('quality', B('check'), mode='e')\n",
    "     .init_variable('shape1', init_on_each_run=list)\n",
    "     .run(batch_size=10, n_epochs=1, shuffle=False, drop_last=False, lazy=True, bar=False)\n",
    "    )\n",
    "\n",
    "shape_ppl.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "short_ppl = (ds.p\n",
    "     .load()\n",
    "     .find_short_cores(SHAPE[1:], dst='short')\n",
    "     .init_variable('short', init_on_each_run=list)\n",
    "     .update_variable('short', B('short'), mode='e')\n",
    "     .run(batch_size=10, n_epochs=1, shuffle=False, drop_last=False, lazy=True, bar=False)\n",
    "    )\n",
    "\n",
    "short_ppl.run()\n",
    "\n",
    "filtered_index = ds.index.create_subset(\n",
    "    ds.indices[np.logical_not(short_ppl.get_variable('short') or shape_ppl.get_variable('quality'))]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df = Dataset(filtered_index, CoreBatch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "bounds = get_bounds(PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_ppl = (Pipeline().load(grayscale=True, df=df).normalize(bounds=bounds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Валидация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_template = (Pipeline()\n",
    "    .to_array(src='uv', dst='uv', channels='first')\n",
    "    .to_array(src='dl', dst='dl', channels='first')\n",
    "    .crop(SHAPE[1:], 200, dst=('dl_crops', 'uv_crops', 'labels_crops'))\n",
    "    .init_model('dynamic', ResNet18, 'model', config={\n",
    "                    'device': 'gpu:2', 'load/path': 'resnet16.torch'\n",
    "                })\n",
    "    .init_variable('loss', init_on_each_run=list)\n",
    "    .call(make_data, save_to=(B('crops_conc'), B('labels_crops_conc')))\n",
    "    .init_variable('proba', init_on_each_run=None)\n",
    "    .init_variable('metrics', init_on_each_run=None)\n",
    "    .predict_model('model', B('crops_conc'), targets=B('labels_crops_conc'), fetches='proba',\n",
    "                 save_to=B('proba', mode='w'))\n",
    "    .call(assemble, save_to=B('proba', mode='w'))\n",
    "    .gather_metrics('class', targets=B('labels'), predictions=B('proba'),\n",
    "                            fmt='proba', axis=-1, save_to=V('metrics', mode='u'), threshold=0.5)\n",
    "    .init_variable('stat', init_on_each_run=list)\n",
    "    .update_variable('stat', (B('dl'), B('uv'), B('proba'), B('labels')), mode='a')\n",
    "    .run(\n",
    "        batch_size=8,\n",
    "        n_epochs=1,\n",
    "        shuffle=False,\n",
    "        drop_last=False,\n",
    "        lazy=True,\n",
    "        bar=True\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ppl = (load_ppl + test_template) << filtered_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 21/22 [00:14<00:00,  2.03it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<well_logs.batchflow.batchflow.pipeline.Pipeline at 0x7f07c4d07e10>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_ppl.reset_iter()\n",
    "test_ppl.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[97 63]\n",
      "  [ 0 11]]]\n",
      "specificity : 1.0\n",
      "sensitivity : 0.14864864864864866\n",
      "accuracy : 0.631578947368421\n"
     ]
    }
   ],
   "source": [
    "metrics = test_ppl.get_variable('metrics')\n",
    "print(metrics._confusion_matrix)\n",
    "\n",
    "for m in ['specificity', 'sensitivity', 'accuracy']:\n",
    "    print(m, ':', metrics.evaluate(m))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = fix_annotation(test_ppl, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df['QC'] = 1 - new_df['QC']\n",
    "new_df.reset_index().to_feather(os.path.join(PATH, 'new_samples.feather'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
