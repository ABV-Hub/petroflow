{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Сопоставление фотографий керна"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* [Задача](#Задача)\n",
    "* [Датасет](#Датасет)\n",
    "* [Архитектура](#Архитектура)\n",
    "* [Обучение](#Обучение)\n",
    "* [Валидация](#Валидация)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задача"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Найти пары фотографий керна в дневном и ультрафиолетовом свете, которые не соответствуют друг другу (смещены, перевернуты, растянуты и пр.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Датасет"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В датасет включены данные по трем скважинам. Каждая скважина представлена набором снимков керна в дневном и ультрафиолетовом свете, а также разметка пар снимков. Пары без дефектов отмечены 1, с дефектами - 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пример хорошей пары:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *\n",
    "\n",
    "plot_pair('/notebooks/data/processed_dataset/417по', '417по_2356.58_2357.56.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пример плохой пары:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_pair('/notebooks/data/processed_dataset/417по', '417по_2360.6_2361.35.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для решения задачи был написан `CoreBatch` с загрузчиком данных и необходимыми аугментациями."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import glob\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "sys.path.insert(0, os.path.join(\"..\", \"..\", \"..\"))\n",
    "\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from well_logs import CoreBatch, CoreIndex\n",
    "from well_logs.batchflow import Dataset, Pipeline, B, V, FilesIndex\n",
    "from well_logs.batchflow.models.torch import ResNet18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = '/notebooks/data/processed_dataset/*'\n",
    "\n",
    "index = CoreIndex(path=os.path.join(PATH, 'samples_dl/*.png'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Предобработка данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузим файл с разметкой и обратим метки: теперь 1 соответствует плохой паре"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = read_annotation(PATH, filename='new_samples.feather')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Удалим из индекса все плохие пары, чтобы использовать только хорошие и их аугментированные варианты."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = index.create_subset(np.intersect1d(df.index.values[df['QC'] == 0], index.indices))\n",
    "ds = Dataset(index, CoreBatch)\n",
    "ds.split(shuffle=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучение будем производить на кропах следующего размера:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SHAPE = (2, 400, 200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Архитектура"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для предсказания будем использовать ResNet18 в базовом варианте"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Обучение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "N_EPOCH = 150\n",
    "\n",
    "model_config = {'initial_block/inputs': 'images',\n",
    "                'inputs/images/shape': SHAPE,\n",
    "                'inputs/labels/classes': 2,\n",
    "                'initial_block/inputs': 'images',\n",
    "                'optimizer': 'Adam',\n",
    "                'output': 'proba',\n",
    "                'device': 'gpu:0',\n",
    "                'loss': 'ce'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "При обучении будем использовать два типа аугментаций: отражение изображений по горизонтали и перемешивание фотографий, поскольку это два наиболее частых и плохих дефекта изображений. Также переведем изображения в ч/б."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bounds = get_bounds(PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bounds = {'215по': {'dl': 158.0, 'uv': 36.0},\n",
    " '3237': {'dl': 161.0, 'uv': 54.0},\n",
    " '3311': {'dl': 160.0, 'uv': 30.0},\n",
    " '417по': {'dl': 175.0, 'uv': 20.0},\n",
    " '4283': {'dl': 161.0, 'uv': 35.0},\n",
    " '509': {'dl': 177.0, 'uv': 19.0},\n",
    " '604': {'dl': 191.0, 'uv': 48.0},\n",
    " '611': {'dl': 168.0, 'uv': 27.0}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_ppl = (Pipeline()\n",
    "    .load(grayscale=True)\n",
    "    .normalize(bounds=bounds)\n",
    "    .fix_shape()\n",
    "    .resize(size=(SHAPE[2], None), src='dl', dst='dl')\n",
    "    .resize(size=(SHAPE[2], None), src='uv', dst='uv')\n",
    "    .mirror_padding((SHAPE[2], SHAPE[1]))\n",
    ")\n",
    "\n",
    "with Pipeline() as p:\n",
    "    augmentation_ppl = p.flip(proba=0.3) + p.shuffle(proba=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_template = (Pipeline()\n",
    "    .to_array(src='uv', dst='uv', channels='first')\n",
    "    .to_array(src='dl', dst='dl', channels='first')\n",
    "    .random_crop(shape=SHAPE[1:], proba=0)\n",
    "     .init_model('dynamic', ResNet18, 'model', model_config)\n",
    "     .init_variable('loss', init_on_each_run=list)\n",
    "     .concatenate(dst='images')\n",
    "     .train_model('model', B('images'), B('labels'), fetches='loss',\n",
    "                 save_to=V('loss', mode='a'))\n",
    "     .run(\n",
    "        batch_size=BATCH_SIZE,\n",
    "        n_epochs=N_EPOCH,\n",
    "        shuffle=True,\n",
    "        drop_last=True,\n",
    "        lazy=True,\n",
    "        bar=True\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ppl = (load_ppl + augmentation_ppl + train_template) << ds.train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ppl.run()\n",
    "train_ppl.get_model_by_name('model').save('resnet16.torch')\n",
    "\n",
    "with open('loss', 'wb') as f:\n",
    "    pickle.dump(train_ppl.get_variable('loss'), f)\n",
    "\n",
    "with open('dataset', 'wb') as f:\n",
    "    pickle.dump(ds, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('loss', 'rb') as f:\n",
    "    loss = pickle.load(f)\n",
    "    \n",
    "with open('dataset', 'rb') as f:\n",
    "    ds = pickle.load(f)\n",
    "\n",
    "plt.plot(loss)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Валидация"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сначала провалидируемся на кропах"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_template = (Pipeline()\n",
    "     .to_array(src='uv', dst='uv', channels='first')\n",
    "     .to_array(src='dl', dst='dl', channels='first')\n",
    "     .random_crop(SHAPE[1:], proba=0)\n",
    "     .init_model('dynamic', ResNet18, 'model', config={\n",
    "                    'device': 'gpu:1', 'load/path': 'resnet16.torch'\n",
    "                })\n",
    "     .init_variable('loss', init_on_each_run=list)\n",
    "     .concatenate(dst='images')\n",
    "     .init_variable('proba', init_on_each_run=None)\n",
    "     .init_variable('metrics', init_on_each_run=None)\n",
    "     .predict_model('model', B('images'), targets=B('labels'), fetches='proba', save_to=B('proba', mode='w'))\n",
    "     .gather_metrics('class', targets=B('labels'), predictions=B('proba'),\n",
    "                     fmt='proba', axis=-1, save_to=V('metrics', mode='u'), threshold=0.5)\n",
    "     .run(\n",
    "        batch_size=BATCH_SIZE,\n",
    "        n_epochs=10,\n",
    "        shuffle=True,\n",
    "        drop_last=False,\n",
    "        lazy=True,\n",
    "        bar=False\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ppl = (load_ppl + augmentation_ppl + test_template) << ds.test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим на примеры предсказаний"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = test_ppl.next_batch()\n",
    "plot_crops_predictions(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ppl.reset_iter()\n",
    "test_ppl.run()\n",
    "\n",
    "metrics = test_ppl.get_variable('metrics')\n",
    "print(metrics._confusion_matrix)\n",
    "\n",
    "for m in ['specificity', 'sensitivity', 'accuracy']:\n",
    "    print(m, ':', metrics.evaluate(m))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Провалидируемся на целых изображениях"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_template = (Pipeline()\n",
    "    .to_array(src='uv', dst='uv', channels='first')\n",
    "    .to_array(src='dl', dst='dl', channels='first')\n",
    "    .crop(SHAPE[1:], 200, dst=('dl_crops', 'uv_crops', 'labels_crops'))\n",
    "    .init_model('dynamic', ResNet18, 'model', config={\n",
    "                    'device': 'gpu:1', 'load/path': 'resnet16.torch'\n",
    "                })\n",
    "    .init_variable('loss', init_on_each_run=list)\n",
    "    .call(make_data, save_to=(B('crops_conc'), B('labels_crops_conc')))\n",
    "    .init_variable('proba', init_on_each_run=None)\n",
    "    .init_variable('metrics', init_on_each_run=None)\n",
    "    .predict_model('model', B('crops_conc'), targets=B('labels_crops_conc'), fetches='proba',\n",
    "                   save_to=B('proba', mode='w'))\n",
    "    .call(assemble, save_to=B('proba', mode='w'))\n",
    "    .gather_metrics('class', targets=B('labels'), predictions=B('proba'),\n",
    "                            fmt='proba', axis=-1, save_to=V('metrics', mode='u'), threshold=0.5)\n",
    "    .init_variable('stat', init_on_each_run=list)\n",
    "    .update_variable('stat', (B('dl'), B('uv'), B('proba'), B('labels')), mode='a')\n",
    "    .run(\n",
    "        batch_size=4,\n",
    "        n_epochs=1,\n",
    "        shuffle=False,\n",
    "        drop_last=False,\n",
    "        lazy=True,\n",
    "        bar=False\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ppl = (load_ppl + augmentation_ppl + test_template) << ds.test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ppl.reset_iter()\n",
    "test_ppl.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = test_ppl.get_variable('metrics')\n",
    "metrics._confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for m in ['specificity', 'sensitivity', 'accuracy']:\n",
    "    print(m, ':', metrics.evaluate(m))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим на ошибки, которые допускает модель."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## False negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_images_predictions(test_ppl, 'fn')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## False positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_images_predictions(test_ppl, 'fp')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
